\section{Appendix}

\subsection{Proof for \cref{thm:online_learning_regret}}

\textbf{\cref{thm:online_learning_regret}.} Given a sequence of functions $\left\{ f_t : t = 0, 1, 2, \dots, T-1 \right\}$ satisfying \cref{asmp:boundedness_smoothness} and \cref{asmp:gradient_dominant}. Online gradient update $\rvx_{t+1} \gets \rvx_{t} - \eta \nabla f_{t}(\rvx_{t})$ with $\eta = 1/L$ satisfies,
\begin{equation*}
\begin{split}
    \sum\limits_{t=0}^{T-1}{\left[ f_t(\rvx_t) - f_t( \rvx_t^* ) \right]} \le \frac{2}{G} \sqrt{L T ( 1 + V_T^f )}.
\end{split}
\end{equation*}
\begin{proof}
First, note that $\left\| \nabla f_t(\rvx ) - \nabla f_t(\rvy) \right\| \le L $ in \cref{asmp:boundedness_smoothness} is equivalent with
\begin{equation*}
\begin{split}
    f_t(\rvx^\prime) \le f_t(\rvx) + \left\langle \nabla f_t(\rvx) , \rvx^\prime - \rvx \right\rangle +  \frac{L}{2} \left\| \rvx^\prime - \rvx \right\|^2, \quad \forall \rvx, \ \rvx^\prime.
\end{split}
\end{equation*}
Let $\rvx^\prime = \rvx_{t+1}$, $\rvx = \rvx_{t}$, and use $\eta = 1/L$,
\begin{equation}
\label{eq:f_t_progress}
\begin{split}
    f_t(\rvx_{t+1}) &\le f_t(\rvx_{t}) + \left\langle \nabla f_t(\rvx_t) , - \eta \nabla f_t(\rvx_t) \right\rangle +  \frac{L \eta^2}{2} \left\| \nabla f_t(\rvx_t) \right\|^2 \\
    &= f_t(\rvx_{t}) - \frac{1}{2 L} \left\| \nabla f_t(\rvx_t) \right\|^2 \\
    &\le f_t(\rvx_{t}) - \frac{G^2}{2 L} \left[ f_t(\rvx_t) - f_t(\rvx_t^*) \right]^2,
\end{split}
\end{equation}
where the last inequality is according to \cref{asmp:gradient_dominant}. Denote $\delta_t \coloneqq f_t(\rvx_t) - f_t( \rvx_t^* )$, $\forall t$.
\begin{equation*}
\begin{split}
    \delta_t &= f_t(\rvx_t) - f_{t-1}(\rvx_t) + f_{t-1}(\rvx_t) - f_t( \rvx_t^* ) \\
    &\le \max\limits_{\rvw}{\left| f_{t}(\rvw) - f_{t-1}(\rvw) \right| } + f_{t-1}(\rvx_t) - f_t( \rvx_t^* ) \\
    &= \max\limits_{\rvw}{\left| f_{t}(\rvw) - f_{t-1}(\rvw) \right| } + f_{t-1}(\rvx_t) - f_{t-1}(\rvx_{t-1}) + f_{t-1}(\rvx_{t-1}) - f_t( \rvx_t^* ) \\
    &\le \max\limits_{\rvw}{\left| f_{t}(\rvw) - f_{t-1}(\rvw) \right| } - \frac{G^2}{2L} \delta_{t-1}^2 + f_{t-1}(\rvx_{t-1}) - f_t( \rvx_t^*) \qquad \left( \text{by \cref{eq:f_t_progress}} \right) \\
    &=  \max\limits_{\rvw}{\left| f_{t}(\rvw) - f_{t-1}(\rvw) \right| } - \frac{G^2}{2L} \delta_{t-1}^2 + f_{t-1}(\rvx_{t-1}) - f_{t-1}(\rvx_{t-1}^*) + f_{t-1}(\rvx_{t-1}^*) - f_t( \rvx_t^* ) \\
    &= \max\limits_{\rvw}{\left| f_{t}(\rvw) - f_{t-1}(\rvw) \right| } - \frac{G^2}{2L} \delta_{t-1}^2 + \delta_{t-1} + f_{t-1}(\rvx_{t-1}^*) - f_t( \rvx_t^*) \\
    &= \max\limits_{\rvw}{\left| f_{t}(\rvw) - f_{t-1}(\rvw) \right| } - \frac{G^2}{2L} \delta_{t-1}^2 + \delta_{t-1} + f_{t-1}(\rvx_{t-1}^*) - f_{t-1}(\rvx_{t}^*) + f_{t-1}(\rvx_{t}^*) - f_t( \rvx_t^*) \\
    &\le \max\limits_{\rvw}{\left| f_{t}(\rvw) - f_{t-1}(\rvw) \right| } - \frac{G^2}{2L} \delta_{t-1}^2 + \delta_{t-1} + f_{t-1}(\rvx_{t}^*) - f_t( \rvx_t^*) \qquad \left(f_{t-1}(\rvx_{t-1}^*) \coloneqq \min\limits_{\rvw}{f_{t-1}(\rvw)} \le f_{t-1}(\rvx_t^*) \right) \\
    &\le \max\limits_{\rvw}{\left| f_{t}(\rvw) - f_{t-1}(\rvw) \right| } - \frac{G^2}{2L} \delta_{t-1}^2 + \delta_{t-1} + \max\limits_{\rvw}{\left| f_{t}(\rvw) - f_{t-1}(\rvw) \right| } \\
    &= - \frac{G^2}{2L} \delta_{t-1}^2 + \delta_{t-1} + 2 \max\limits_{\rvw}{\left| f_{t}(\rvw) - f_{t-1}(\rvw) \right| }.
\end{split}
\end{equation*}
Rearranging and summing up from $1$ to $T$,
\begin{equation}
\label{eq:delta_t_upper_bound}
\begin{split}
    \frac{G^2}{2L} \cdot \sum\limits_{t=1}^{T}{ \delta_{t-1}^2} &\le \sum\limits_{t=1}^{T}{\left[ \delta_{t-1} - \delta_{t} + 2 \max\limits_{\rvw}{\left| f_{t}(\rvw) - f_{t-1}(\rvw) \right|} \right] } \\
    &= \sum\limits_{t=1}^{T}{ \left[ \delta_{t-1} - \delta_{t} \right] } + 2 \sum\limits_{t=0}^{T-1}{ \max\limits_{\rvw}{\left| f_{t+1}(\rvw) - f_{t}(\rvw) \right| } } \\
    &= \delta_0 - \delta_{T} + 2 V_T^f \qquad \left( \text{\cref{defi:function_variation}} \right) \\
    &\le 2 + 2 V_T^f \qquad \left(\text{\cref{asmp:boundedness_smoothness}}\right).
\end{split}
\end{equation}
According to the Root-Mean Square-Arithmetic Mean inequality, the regret is upper bounded as
\begin{equation*}
\begin{split}
    \sum\limits_{t=0}^{T-1}{\left[ f_t(\rvx_t) - f_t( \rvx_t^*) \right]} = \sum\limits_{t=1}^{T}{ \delta_{t-1}} &\le \sqrt{T \sum\limits_{t=1}^{T}{ \delta_{t-1}^2}} \\
    &\le \frac{2}{G} \sqrt{L T ( 1 + V_T^f)}. \qquad \left(\text{by \cref{eq:delta_t_upper_bound}}\right) \qedhere
\end{split}
\end{equation*}
\end{proof}